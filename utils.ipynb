{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/as3ek/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import json\n",
    "import torch\n",
    "from scipy.misc import imread, imresize\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from random import seed, choice, sample\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from random import randint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/caption_data_0_100.csv') \n",
    "image_folder = 'data/images/' \n",
    "captions_per_image = 7000\n",
    "min_word_freq = 5\n",
    "output_folder = 'data/proc_data_files/'\n",
    "max_len = 20\n",
    "\n",
    "train_image_paths = []\n",
    "train_image_captions = []\n",
    "val_image_paths = []\n",
    "val_image_captions = []\n",
    "test_image_paths = []\n",
    "test_image_captions = []\n",
    "num_images_to_train = 20\n",
    "word_freq = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in dataset['ImageName'][:num_images_to_train]:\n",
    "    captions = []\n",
    "    for c in dataset[dataset['ImageName'] == img]['Caption']:\n",
    "        # Updating word freq\n",
    "        c = str(c)\n",
    "        \n",
    "        tokens = word_tokenize(c)\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "        \n",
    "        word_freq.update(tokens)\n",
    "        if len(tokens) <= max_len:\n",
    "            captions.append(tokens)\n",
    "    \n",
    "    if len(captions) == 0:\n",
    "        continue\n",
    "    \n",
    "    path = os.path.join(img)\n",
    "    \n",
    "    if randint(0, 10) < 9:\n",
    "        train_image_paths.append(path)\n",
    "        train_image_captions.append(captions)\n",
    "    \n",
    "    else:\n",
    "        val_image_paths.append(path)\n",
    "        val_image_captions.append(captions)\n",
    "        \n",
    "    if randint(0, 10) < 5:\n",
    "        test_image_paths.append(path)\n",
    "        test_image_captions.append(captions)\n",
    "        \n",
    "# Sanity check\n",
    "assert len(train_image_paths) == len(train_image_captions)\n",
    "assert len(val_image_paths) == len(val_image_captions)\n",
    "assert len(test_image_paths) == len(test_image_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word map\n",
    "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
    "word_map = {k: v + 1 for v, k in enumerate(words)}\n",
    "word_map['<unk>'] = len(word_map) + 1\n",
    "word_map['<start>'] = len(word_map) + 1\n",
    "word_map['<end>'] = len(word_map) + 1\n",
    "word_map['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/17 [00:00<00:02,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading TRAIN images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:01<00:00, 14.14it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 26.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading VAL images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|██▋       | 3/11 [00:00<00:00, 28.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading TEST images and captions, storing to file...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 27.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create a base/root name for all output files\n",
    "base_filename = 'meme_' + str(captions_per_image) + '_cap_per_img_' + str(min_word_freq) + '_min_word_freq'\n",
    "\n",
    "# Save word map to a JSON\n",
    "with open(os.path.join(output_folder, 'WORDMAP_' + base_filename + '.json'), 'w') as j:\n",
    "    json.dump(word_map, j)\n",
    "    \n",
    "# Sample captions for each image, save images to HDF5 file, and captions and their lengths to JSON files\n",
    "seed(123)\n",
    "for impaths, imcaps, split in [(train_image_paths, train_image_captions, 'TRAIN'),\n",
    "                               (val_image_paths, val_image_captions, 'VAL'),\n",
    "                               (test_image_paths, test_image_captions, 'TEST')]:\n",
    "\n",
    "    with h5py.File(os.path.join(output_folder, split + '_IMAGES_' + base_filename + '.hdf5'), 'a') as h:\n",
    "        # Make a note of the number of captions we are sampling per image\n",
    "        h.attrs['captions_per_image'] = captions_per_image\n",
    "\n",
    "        # Create dataset inside HDF5 file to store images\n",
    "        images = h.create_dataset('images', (len(impaths), 3, 256, 256), dtype='uint8')\n",
    "\n",
    "        print(\"\\nReading %s images and captions, storing to file...\\n\" % split)\n",
    "\n",
    "        enc_captions = []\n",
    "        caplens = []\n",
    "\n",
    "        for i, path in enumerate(tqdm(impaths)):\n",
    "\n",
    "            # Sample captions\n",
    "            if len(imcaps[i]) < captions_per_image:\n",
    "                captions = imcaps[i] + [choice(imcaps[i]) for _ in range(captions_per_image - len(imcaps[i]))]\n",
    "            else:\n",
    "                captions = sample(imcaps[i], k=captions_per_image)\n",
    "\n",
    "            # Sanity check\n",
    "            assert len(captions) == captions_per_image\n",
    "\n",
    "            # Read images\n",
    "            img = imread(impaths[i])\n",
    "            if len(img.shape) == 2:\n",
    "                img = img[:, :, np.newaxis]\n",
    "                img = np.concatenate([img, img, img], axis=2)\n",
    "            img = imresize(img, (256, 256))\n",
    "            img = img.transpose(2, 0, 1)\n",
    "            assert img.shape == (3, 256, 256)\n",
    "            assert np.max(img) <= 255\n",
    "\n",
    "            # Save image to HDF5 file\n",
    "            images[i] = img\n",
    "\n",
    "            for j, c in enumerate(captions):\n",
    "                # Encode captions\n",
    "                enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in c] + [\n",
    "                    word_map['<end>']] + [word_map['<pad>']] * (max_len - len(c))\n",
    "\n",
    "                # Find caption lengths\n",
    "                c_len = len(c) + 2\n",
    "\n",
    "                enc_captions.append(enc_c)\n",
    "                caplens.append(c_len)\n",
    "\n",
    "        # Sanity check\n",
    "        assert images.shape[0] * captions_per_image == len(enc_captions) == len(caplens)\n",
    "\n",
    "        # Save encoded captions and their lengths to JSON files\n",
    "        with open(os.path.join(output_folder, split + '_CAPTIONS_' + base_filename + '.json'), 'w') as j:\n",
    "            json.dump(enc_captions, j)\n",
    "\n",
    "        with open(os.path.join(output_folder, split + '_CAPLENS_' + base_filename + '.json'), 'w') as j:\n",
    "            json.dump(caplens, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
